{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../tfmodels')\n",
    "import bottleneck as bn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from past.builtins import xrange\n",
    "import pandas as pd\n",
    "\n",
    "#from data import read_data\n",
    "from memory_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"nb_words\", 20001, \"term number in input sequence(zero mask)\")\n",
    "flags.DEFINE_integer(\"mem_size\", 10, \"the memory length of input sequence\")\n",
    "flags.DEFINE_integer(\"nhop\", 6, \"the number of hop layers\")\n",
    "flags.DEFINE_integer(\"embedding_size\", 150, \"word embedding size\")\n",
    "flags.DEFINE_float(\"init_hid\", 0.1, \"init_hid for q\")\n",
    "flags.DEFINE_float(\"init_std\", 0.05, \"init_std for training variable\")\n",
    "\n",
    "flags.DEFINE_float(\"linear_ratio\", 0.5, \"keep probability of drop out [0.9]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.01, \"learning rate [0.001]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 1024, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 50.0, \"clip gradients to this norm\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 100, \"number of epoch to use during training\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", True, \"save checkpoint or not in each epoch\")\n",
    "flags.DEFINE_integer(\"print_step\", 500, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", True, \"use lr annealing or not after each epoch [False]\")\n",
    "#flags.DEFINE_string(\"current_task_name\", '_season_prediction', \"current task name [self_prediction]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h5_file_path = 'Data/url_first_24.h5'\n",
    "h5f = h5py.File(h5_file_path, 'r')\n",
    "urls = np.array(h5f['urls'])\n",
    "#clicks = h5f['clicks']\n",
    "#seasons = h5f['seasons']\n",
    "seq_len = np.array(h5f['seq_len'])\n",
    "#seq_len = np.array(seq_len)\n",
    "#user_id = h5f['user_id']\n",
    "id_map_path = 'Data/seq_url_map_24.csv'\n",
    "id_map_df = pd.read_csv(id_map_path)\n",
    "id_dict = dict(zip(id_map_df.id, id_map_df.page_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "step = 1\n",
    "samples = 0\n",
    "for i in xrange(len(seq_len)):\n",
    "    samples += len(range(0, seq_len[i] - maxlen, step))\n",
    "    \n",
    "previous_urls = np.empty(shape=(samples, maxlen))\n",
    "next_urls = np.empty(shape=(samples))\n",
    "global_step = 0\n",
    "for i in xrange(len(urls)):\n",
    "    url = urls[i][0:seq_len[i]]\n",
    "    for j in range(0, seq_len[i] - maxlen, step):\n",
    "        previous_urls[global_step] = url[j: j + maxlen]\n",
    "        next_urls[global_step] = url[j + maxlen]\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idxs = np.arange(0, samples)\n",
    "#idxs = idxs[0:2000]\n",
    "train_idxs, test_idxs = train_test_split(idxs, test_size=10240, random_state=52)\n",
    "test_idxs = np.sort(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/memory/Ain_c/embedding_table:0</td>\n",
       "      <td>[20001, 150]</td>\n",
       "      <td>3000150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/memory/Ain_t/W:0</td>\n",
       "      <td>[10, 150]</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/memory/Cin_c/embedding_table:0</td>\n",
       "      <td>[20001, 150]</td>\n",
       "      <td>3000150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/memory/Cin_t/W:0</td>\n",
       "      <td>[10, 150]</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/momory_hops/hops_h/W:0</td>\n",
       "      <td>[150, 150]</td>\n",
       "      <td>22500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/prediction/fc/W:0</td>\n",
       "      <td>[150, 20001]</td>\n",
       "      <td>3000150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        variable_name variable_shape  parameters\n",
       "0                   global/Variable:0             []         1.0\n",
       "1  gpu/memory/Ain_c/embedding_table:0   [20001, 150]   3000150.0\n",
       "2                gpu/memory/Ain_t/W:0      [10, 150]      1500.0\n",
       "3  gpu/memory/Cin_c/embedding_table:0   [20001, 150]   3000150.0\n",
       "4                gpu/memory/Cin_t/W:0      [10, 150]      1500.0\n",
       "5          gpu/momory_hops/hops_h/W:0     [150, 150]     22500.0\n",
       "6               gpu/prediction/fc/W:0   [150, 20001]   3000150.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 1, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 4.2602043)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.51367188)\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    mem_model = MemN2NModel(FLAGS, session, 'memn2n_url_prediction')\n",
    "    mem_model.build_model(type='self', accK=5, export_attention=True)\n",
    "    mem_model.build_model_summary()\n",
    "    display(mem_model.model_summary())\n",
    "    mem_model.run([previous_urls,next_urls], train_idxs, test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/memory/Ain_c/embedding_table:0</td>\n",
       "      <td>[20001, 150]</td>\n",
       "      <td>3000150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/memory/Ain_t/W:0</td>\n",
       "      <td>[10, 150]</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/memory/Cin_c/embedding_table:0</td>\n",
       "      <td>[20001, 150]</td>\n",
       "      <td>3000150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/memory/Cin_t/W:0</td>\n",
       "      <td>[10, 150]</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/momory_hops/hops_h/W:0</td>\n",
       "      <td>[150, 150]</td>\n",
       "      <td>22500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/prediction/fc/W:0</td>\n",
       "      <td>[150, 20001]</td>\n",
       "      <td>3000150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        variable_name variable_shape  parameters\n",
       "0                   global/Variable:0             []         1.0\n",
       "1  gpu/memory/Ain_c/embedding_table:0   [20001, 150]   3000150.0\n",
       "2                gpu/memory/Ain_t/W:0      [10, 150]      1500.0\n",
       "3  gpu/memory/Cin_c/embedding_table:0   [20001, 150]   3000150.0\n",
       "4                gpu/memory/Cin_t/W:0      [10, 150]      1500.0\n",
       "5          gpu/momory_hops/hops_h/W:0     [150, 150]     22500.0\n",
       "6               gpu/prediction/fc/W:0   [150, 20001]   3000150.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model ...\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    mem_model = MemN2NModel(FLAGS, session, 'memn2n_url_prediction')\n",
    "    mem_model.build_model(type='self', accK=5, export_attention=True)\n",
    "    mem_model.build_model_summary()\n",
    "    display(mem_model.model_summary())\n",
    "    mem_model.model_restore()\n",
    "    _, testMetric, results = mem_model.model_run([previous_urls,next_urls], \n",
    "                                                  test_idxs, run_type='self',\n",
    "                                                  mode='test', shuffle=False, save_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction = np.concatenate([np.argsort(-results[i][0])[:,:5] for i in range(0, len(results))])\n",
    "#prediction = np.concatenate([bn.argpartition(-results[0][0], 5)[:,:5] for i in range(0, len(results))])\n",
    "attention = np.concatenate([results[i][1] for i in range(0, len(results))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hulu.com/tv: 0.113912783563\n",
      "$: 0.00927216187119\n",
      "hulu.com/: 0.0386288017035\n",
      "hulu.com/catfish-the-tv-show: 0.0580177605152\n",
      "hulu.com/watch/433554 (Catfish: The TV Show) (episode): 0.0368508473039\n",
      "hulu.com/watch/434899 (Catfish: The TV Show) (episode): 0.0706789940596\n",
      "hulu.com/watch/439797 (Catfish: The TV Show) (episode): 0.0862120464444\n",
      "hulu.com/watch/439798 (Catfish: The TV Show) (episode): 0.157057926059\n",
      "$: 0.0237574372441\n",
      "hulu.com/: 0.405611276627\n",
      "\n",
      "prediction:\n",
      "hulu.com/catfish-the-tv-show\n",
      "hulu.com/search?q=catfish%3a the tv show\n",
      "$\n",
      "hulu.com/tv\n",
      "hulu.com/\n",
      "\n",
      "groundtruth:\n",
      "hulu.com/catfish-the-tv-show\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0,10240)\n",
    "temp_idx = test_idxs[i]\n",
    "if next_urls[temp_idx] in prediction[i]:\n",
    "    print('\\n'.join(['{}: {}'.format(id_dict[id], attention[i][0][idx]) for idx, id \n",
    "           in enumerate(previous_urls[temp_idx])]))\n",
    "    print('\\nprediction:')\n",
    "    print('\\n'.join([id_dict[id] for id in prediction[i]]))\n",
    "    print('\\ngroundtruth:')\n",
    "    print(id_dict[next_urls[temp_idx]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
