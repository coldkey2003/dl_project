{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../tfmodels')\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from past.builtins import xrange\n",
    "import pandas as pd\n",
    "\n",
    "#from data import read_data\n",
    "from memory_model import *\n",
    "from tf_object import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"nb_words\", 100001, \"term number in input sequence(zero mask)\")\n",
    "flags.DEFINE_integer(\"mem_size\", 400, \"the memory length of input sequence\")\n",
    "flags.DEFINE_integer(\"nhop\", 6, \"the number of hop layers\")\n",
    "flags.DEFINE_integer(\"embedding_size\", 100, \"word embedding size\")\n",
    "flags.DEFINE_float(\"init_hid\", 0.1, \"init_hid for q\")\n",
    "flags.DEFINE_float(\"init_std\", 0.05, \"init_std for training variable\")\n",
    "\n",
    "flags.DEFINE_float(\"linear_ratio\", 0.5, \"keep probability of drop out [0.9]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.01, \"learning rate [0.001]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 1024, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 5.0, \"clip gradients to this norm\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 100, \"number of epoch to use during training\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", False, \"save checkpoint or not in each epoch\")\n",
    "flags.DEFINE_integer(\"print_step\", 500, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", True, \"use lr annealing or not after each epoch [False]\")\n",
    "#flags.DEFINE_string(\"current_task_name\", '_season_prediction', \"current task name [self_prediction]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load training h5 file\n",
    "#h5_file_path = '../RData/episode_seq_30d.h5'\n",
    "#h5_file_path = 'Data/episode_seq_28_35.h5'\n",
    "#h5_file_path = '/home/host/CORP/wei.wang/Data/episode_seq_30d.h5'   ##elscvgpu01\n",
    "h5_file_path = '/mnt/host/storage/wei.wang/Data/episode_seq_30d.h5'  #elscvgpu02\n",
    "h5f = h5py.File(h5_file_path, 'r')\n",
    "videos = np.array(h5f['videos'])\n",
    "viewthru = np.array(h5f['viewthru'])\n",
    "hour_ids = np.array(h5f['hour_ids'])\n",
    "#seasons = np.array(h5f['seasons'])\n",
    "seq_len = h5f['seq_len']\n",
    "seq_len = np.array(seq_len)\n",
    "cancel_days = np.array(h5f['cancel_days'])\n",
    "split_index = np.array(h5f['split_index'])\n",
    "user_id = np.array(h5f['user_id'])\n",
    "\n",
    "#load the user attributes\n",
    "user_attr_path = '../RData/user_attr.csv'\n",
    "user_attr_df = pd.read_csv(user_attr_path)\n",
    "user_attr_dict = dict(zip(user_attr_df['userid'].tolist(), user_attr_df['id'].tolist()))\n",
    "id_list = np.array([user_attr_dict[u] for u in user_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idxs = np.arange(0, len(cancel_days))\n",
    "threshold = 60\n",
    "cancel_days[cancel_days<=threshold] = 1\n",
    "cancel_days[cancel_days>=threshold] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#using balance data in training stage\n",
    "balance_flag = True\n",
    "#training for debug&init parameter\n",
    "training_flag = False\n",
    "\n",
    "if balance_flag:\n",
    "    train_cancel_days = cancel_days[:split_index]\n",
    "    positive_length = sum(train_cancel_days==1)\n",
    "    #[-positive_length:]\n",
    "    train_idxs = np.append(np.random.choice(np.where(train_cancel_days == 0)[0], int(positive_length*3.0), replace=False),\n",
    "                     np.random.choice(np.where(train_cancel_days == 1)[0], positive_length, replace=False))\n",
    "else:\n",
    "    #train_idxs = idxs[3142375:3303991]\n",
    "    train_idxs = idxs[split_index[0]-500000:split_index[0]]\n",
    "#print(len(train_idxs))\n",
    "\n",
    "if training_flag:\n",
    "    train_idxs, test_idxs = train_test_split(train_idxs, test_size=0.2, random_state=23)\n",
    "    test_idxs = np.sort(test_idxs)\n",
    "else:\n",
    "    test_idxs = idxs[split_index:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/memory/Ain_c/embedding_table:0</td>\n",
       "      <td>[100000, 100]</td>\n",
       "      <td>10000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/memory/Ain_c_vt/embedding_table:0</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/memory/Ain_t/W:0</td>\n",
       "      <td>[400, 100]</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/memory/questions/embedding_table:0</td>\n",
       "      <td>[2000, 100]</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/memory/Cin_c/embedding_table:0</td>\n",
       "      <td>[100000, 100]</td>\n",
       "      <td>10000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/memory/Cin_c_vt/embedding_table:0</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpu/memory/Cin_t/W:0</td>\n",
       "      <td>[400, 100]</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpu/momory_hops/hops_h/W:0</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpu/prediction/fc/W:0</td>\n",
       "      <td>[100, 2]</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            variable_name variable_shape  parameters\n",
       "0                       global/Variable:0             []         1.0\n",
       "1      gpu/memory/Ain_c/embedding_table:0  [100000, 100]  10000000.0\n",
       "2   gpu/memory/Ain_c_vt/embedding_table:0     [100, 100]     10000.0\n",
       "3                    gpu/memory/Ain_t/W:0     [400, 100]     40000.0\n",
       "4  gpu/memory/questions/embedding_table:0    [2000, 100]    200000.0\n",
       "5      gpu/memory/Cin_c/embedding_table:0  [100000, 100]  10000000.0\n",
       "6   gpu/memory/Cin_c_vt/embedding_table:0     [100, 100]     10000.0\n",
       "7                    gpu/memory/Cin_t/W:0     [400, 100]     40000.0\n",
       "8              gpu/momory_hops/hops_h/W:0     [100, 100]     10000.0\n",
       "9                   gpu/prediction/fc/W:0       [100, 2]       200.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 1, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.52771747)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.75488281)\n",
      "('epoch time:', 0.9475398341814677)\n",
      "('Epoch', 1, 'training accuracy:', 0.74976573523723389)\n",
      "('Epoch', 1, '... test ...')\n",
      "('Epoch', 1, 'test accuracy:', 0.96181515200780365)\n",
      "{'valid_los': 0.30948261477427452, 'loss': 0.54764589451003254, 'epoch': 0, 'valid_perplexity': 1.3627198805761858, 'best_auc': 0.67522586929033701, 'learning_rate': 0.01, 'best_accuracy': 0.74976573523723389, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 2, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.55668682)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.73144531)\n",
      "('epoch time:', 0.903827166557312)\n",
      "('Epoch', 2, 'training accuracy:', 0.75000272400886936)\n",
      "('Epoch', 2, '... test ...')\n",
      "('Epoch', 2, 'test accuracy:', 0.96181515200780365)\n",
      "{'valid_los': 0.30237564585534871, 'loss': 0.53882717117126933, 'epoch': 1, 'valid_perplexity': 1.3530694061701793, 'best_auc': 0.68638350969571527, 'learning_rate': 0.01, 'best_accuracy': 0.75000272400886936, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 3, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.53900349)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.7578125)\n",
      "('epoch time:', 0.9019958337148031)\n",
      "('Epoch', 3, 'training accuracy:', 0.75000544801773872)\n",
      "('Epoch', 3, '... test ...')\n",
      "('Epoch', 3, 'test accuracy:', 0.96181515200780365)\n",
      "{'valid_los': 0.29836947323732932, 'loss': 0.53679046378975015, 'epoch': 2, 'valid_perplexity': 1.3476596200687003, 'best_auc': 0.68868569408904012, 'learning_rate': 0.01, 'best_accuracy': 0.75000544801773872, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 4, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.54755533)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.74511719)\n",
      "('epoch time:', 0.9016182502110799)\n",
      "('Epoch', 4, 'training accuracy:', 0.75000272400886936)\n",
      "('Epoch', 4, '... test ...')\n",
      "('Epoch', 4, 'test accuracy:', 0.96181515200780365)\n",
      "{'valid_los': 0.28004797158871525, 'loss': 0.53504165009561266, 'epoch': 3, 'valid_perplexity': 1.3231932864990772, 'best_auc': 0.69701717336721603, 'learning_rate': 0.01, 'best_accuracy': 0.75000544801773872, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 5, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.50767034)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.77832031)\n",
      "('epoch time:', 0.9021023313204447)\n",
      "('Epoch', 5, 'training accuracy:', 0.75003132610199774)\n",
      "('Epoch', 5, '... test ...')\n",
      "('Epoch', 5, 'test accuracy:', 0.96172370346285152)\n",
      "{'valid_los': 0.28882054239148108, 'loss': 0.53418384267759178, 'epoch': 4, 'valid_perplexity': 1.334852157656804, 'best_auc': 0.69858752650686984, 'learning_rate': 0.01, 'best_accuracy': 0.75003132610199774, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 6, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.54730868)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.73339844)\n",
      "('epoch time:', 0.902548615137736)\n",
      "('Epoch', 6, 'training accuracy:', 0.75008716828381994)\n",
      "('Epoch', 6, '... test ...')\n",
      "('Epoch', 6, 'test accuracy:', 0.96171354251341246)\n",
      "{'valid_los': 0.32469724736704397, 'loss': 0.5318606461757639, 'epoch': 5, 'valid_perplexity': 1.3836116904817293, 'best_auc': 0.70086679290059206, 'learning_rate': 0.006666666666666667, 'best_accuracy': 0.75008716828381994, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 7, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.52753365)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.75585938)\n",
      "('epoch time:', 0.9056826670964558)\n",
      "('Epoch', 7, 'training accuracy:', 0.75016207852772765)\n",
      "('Epoch', 7, '... test ...')\n",
      "('Epoch', 7, 'test accuracy:', 0.96164241586733867)\n",
      "{'valid_los': 0.28752601361821251, 'loss': 0.53043777716790241, 'epoch': 6, 'valid_perplexity': 1.3331252711239705, 'best_auc': 0.70340785720501586, 'learning_rate': 0.0044444444444444444, 'best_accuracy': 0.75016207852772765, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 8, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.53996515)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.73632812)\n",
      "('epoch time:', 0.9048219005266825)\n",
      "('Epoch', 8, 'training accuracy:', 0.75024788480711291)\n",
      "('Epoch', 8, '... test ...')\n",
      "('Epoch', 8, 'test accuracy:', 0.96147984067631276)\n",
      "{'valid_los': 0.31516264504755326, 'loss': 0.53006190650656759, 'epoch': 7, 'valid_perplexity': 1.3704821949727868, 'best_auc': 0.704065108326279, 'learning_rate': 0.0044444444444444444, 'best_accuracy': 0.75024788480711291, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 9, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.52111018)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.76074219)\n",
      "('epoch time:', 0.9036056995391846)\n",
      "('Epoch', 9, 'training accuracy:', 0.75023426476276611)\n",
      "('Epoch', 9, '... test ...')\n",
      "('Epoch', 9, 'test accuracy:', 0.96162209396846043)\n",
      "{'valid_los': 0.31448765635160947, 'loss': 0.52925428043943712, 'epoch': 8, 'valid_perplexity': 1.3695574471154734, 'best_auc': 0.70541162689477521, 'learning_rate': 0.002962962962962963, 'best_accuracy': 0.75024788480711291, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 10, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.53157568)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.7578125)\n",
      "('epoch time:', 0.9020963827768962)\n",
      "('Epoch', 10, 'training accuracy:', 0.75026831487363321)\n",
      "('Epoch', 10, '... test ...')\n",
      "('Epoch', 10, 'test accuracy:', 0.96158145017070396)\n",
      "{'valid_los': 0.30867479944826043, 'loss': 0.52893110232466922, 'epoch': 9, 'valid_perplexity': 1.3616194990839485, 'best_auc': 0.70671000009434259, 'learning_rate': 0.002962962962962963, 'best_accuracy': 0.75026831487363321, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 11, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.52349973)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.75878906)\n",
      "('epoch time:', 0.9022997657457987)\n",
      "('Epoch', 11, 'training accuracy:', 0.75025333282485163)\n",
      "('Epoch', 11, '... test ...')\n",
      "('Epoch', 11, 'test accuracy:', 0.96160177206958219)\n",
      "{'valid_los': 0.28825359316574539, 'loss': 0.52869683756190311, 'epoch': 10, 'valid_perplexity': 1.3340955787507272, 'best_auc': 0.70671000009434259, 'learning_rate': 0.002962962962962963, 'best_accuracy': 0.75026831487363321, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 12, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.53502977)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.74414062)\n",
      "('epoch time:', 0.9007981499036153)\n",
      "('Epoch', 12, 'training accuracy:', 0.75029555496232692)\n",
      "('Epoch', 12, '... test ...')\n",
      "('Epoch', 12, 'test accuracy:', 0.96160177206958219)\n",
      "{'valid_los': 0.28963716916583687, 'loss': 0.52856582976034172, 'epoch': 11, 'valid_perplexity': 1.3359426788823647, 'best_auc': 0.70671000009434259, 'learning_rate': 0.002962962962962963, 'best_accuracy': 0.75029555496232692, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 13, '... training ...')\n",
      "('Minibatch', 500, '/', 'loss:', 0.52040195)\n",
      "('Minibatch', 500, '/', 'accuracy:', 0.75585938)\n",
      "('epoch time:', 0.9088928659756979)\n",
      "('Epoch', 13, 'training accuracy:', 0.75029555496232692)\n",
      "('Epoch', 13, '... test ...')\n",
      "('Epoch', 13, 'test accuracy:', 0.96141887497967815)\n",
      "{'valid_los': 0.30578779984326737, 'loss': 0.52798055091717377, 'epoch': 12, 'valid_perplexity': 1.3576941730616696, 'best_auc': 0.70677271712238732, 'learning_rate': 0.0019753086419753087, 'best_accuracy': 0.75029555496232692, 'best_test_accuracy': 0.96181515200780365}\n",
      "('Epoch', 14, '... training ...')\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    #mem_model = MemN2NModel(FLAGS, session, 'memn2n_model_churn_prediction')\n",
    "    mem_model = MemN2NUserModel(FLAGS, session, 'memn2n_user_model_churn_prediction')\n",
    "    mem_model.build_model(type='churn', accK=1, nb_class=2)\n",
    "    mem_model.build_model_summary()\n",
    "    display(mem_model.model_summary())\n",
    "    #we can init from a well-trained model by using model_restore()\n",
    "    #mem_model.model_restore()\n",
    "    #mem_model.run([videos,cancel_days], train_idxs, test_idxs)\n",
    "    mem_model.run([videos,viewthru,id_list,cancel_days], train_idxs, test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "res = {}\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    mem_model = MemN2NUserModel(FLAGS, session, 'memn2n_user_model_churn_prediction')\n",
    "    mem_model.build_model(type='churn', accK=1, nb_class=2)\n",
    "    mem_model.build_model_summary()\n",
    "    display(mem_model.model_summary())\n",
    "    mem_model.model_restore()\n",
    "    epochTestLoss, epochTestMetric, result = mem_model.model_run([videos,viewthru,id_list,cancel_days], test_idxs, run_type='self',\n",
    "                                                                 mode='test', shuffle=False, save_metric=True)\n",
    "    \n",
    "    #for var in tf.trainable_variables():\n",
    "    #    res[var.name] = var.eval()\n",
    "\n",
    "result = np.concatenate(result)\n",
    "y = np.array(cancel_days[test_idxs])[0:len(result)]\n",
    "pred = result[:,1]\n",
    "roc_auc_score(y,pred)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
